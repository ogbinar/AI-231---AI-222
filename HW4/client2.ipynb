{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e1b515-ac1b-4bab-877e-b69218d5f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import validators\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6aa1d2e-0fe9-4e18-8560-3c1dec0e4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tritonclient.http import InferenceServerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43969ab1-ac92-4590-8961-9af58ab83029",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'InferenceServerClient' has no attribute 'Infer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYolov8x\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m \u001b[43minfer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[22], line 30\u001b[0m, in \u001b[0;36minfer_model\u001b[1;34m(url, image_path, model)\u001b[0m\n\u001b[0;32m     27\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Send inference request\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[43mInferenceServerClient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInfer\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT0\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUINT8\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     31\u001b[0m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_data_from_numpy(image)\n\u001b[0;32m     32\u001b[0m outputs \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39minfer(model_name\u001b[38;5;241m=\u001b[39mmodel, inputs\u001b[38;5;241m=\u001b[39minputs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'InferenceServerClient' has no attribute 'Infer'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import validators\n",
    "import matplotlib.pyplot as plt\n",
    "from tritonclient.http import InferenceServerClient\n",
    "\n",
    "# Define function to download image if URL provided\n",
    "def get_image(image_path):\n",
    "    if validators.url(image_path):\n",
    "        with urllib.request.urlopen(image_path) as url_response:\n",
    "            img_array = np.array(bytearray(url_response.read()), dtype=np.uint8)\n",
    "            image = cv2.imdecode(img_array, -1)\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "    return image\n",
    "\n",
    "# Define function to perform inference\n",
    "def infer_model(url, image_path, model):\n",
    "    # Create InferenceServerClient instance\n",
    "    client = InferenceServerClient(url=url)\n",
    "\n",
    "    # Download or read image\n",
    "    image = get_image(image_path)\n",
    "\n",
    "    # Preprocess image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Send inference request\n",
    "    inputs = [InferenceServerClient.InferInput(\"INPUT0\", [-1, -1, 3], \"UINT8\")]\n",
    "    inputs[0].set_data_from_numpy(image)\n",
    "    outputs = client.infer(model_name=model, inputs=inputs)\n",
    "\n",
    "    # Parse outputs\n",
    "    names = outputs[\"names\"].tobytes().decode('utf-32').split(\"|\")[:-1]\n",
    "    bboxes = outputs[\"bboxes\"]\n",
    "    probs = outputs[\"probs\"]\n",
    "\n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        if probs[i] > 0.5:\n",
    "            x1, y1, x2, y2 = bboxes[i]\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            color = np.random.rand(3,)\n",
    "            rect = plt.Rectangle((x1, y1), w, h, fill=False, edgecolor=color)\n",
    "            ax.add_patch(rect)\n",
    "            color = np.append(color, 0.5)\n",
    "            ax.text(x1, y1, f\"{names[i]} {probs[i]:.2f}\", color='black', fontsize=10, bbox=dict(facecolor=color, alpha=0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# User input and server configuration\n",
    "image_path = \"bus.jpg\"\n",
    "url = \"202.92.159.241:8008\"\n",
    "model = \"Yolov8x\"\n",
    "\n",
    "# Run inference\n",
    "infer_model(url, image_path, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8465327a-a807-4955-93a6-559da251896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_model(url=\"202.92.159.241:8008\", \n",
    "                image=\"bus.jpg\", \n",
    "                model=\"Yolov8x\"):\n",
    "    with InferenceServerClient(url, model) as client:\n",
    "        if validators.url(image):\n",
    "            with urllib.request.urlopen(image) as url_response:\n",
    "                img_array = np.array(bytearray(url_response.read()), \n",
    "                                     dtype=np.uint8)\n",
    "                image = cv2.imdecode(img_array, -1)\n",
    "        else:\n",
    "            image = cv2.imread(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        outputs = client.infer(inputs=image,model_name=model)\n",
    "        for k, v in outputs.items():\n",
    "            if k == \"names\":\n",
    "                names = v.tobytes().decode('utf-32').split(\"|\")\n",
    "                names = names[:-1]\n",
    "            elif k == \"bboxes\":\n",
    "                bboxes = v\n",
    "            elif k == \"probs\":\n",
    "                probs = v\n",
    "        \n",
    "        # Plotting\n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        for i in range(len(names)):\n",
    "            if probs[i] > 0.5:\n",
    "                x1, y1, x2, y2 = bboxes[i]\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                # make the color random\n",
    "                color = np.random.rand(3,)\n",
    "                rect = plt.Rectangle((x1, y1), w, h, fill=False, color=color)\n",
    "                ax.add_patch(rect)\n",
    "                # use the color and add transparency of 0.5\n",
    "                color = np.append(color, 0.5)\n",
    "                # add text with white background\n",
    "                ax.text(x1, y1, f\"{names[i]} {probs[i]:.2f}\", color='black', fontsize=10, bbox=dict(facecolor=color, alpha=0.5))\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc721ec7-f69a-425b-b794-540960b163d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute '_get_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minfer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m, in \u001b[0;36minfer_model\u001b[1;34m(url, image, model)\u001b[0m\n\u001b[0;32m     11\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image)\n\u001b[0;32m     12\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\tritonclient\\http\\_client.py:1414\u001b[0m, in \u001b[0;36mInferenceServerClient.infer\u001b[1;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, headers, query_params, request_compression_algorithm, response_compression_algorithm, parameters)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1319\u001b[0m     model_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1334\u001b[0m ):\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run synchronous inference using the supplied 'inputs' requesting\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;124;03m    the outputs specified by 'outputs'.\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m        If server fails to perform inference.\u001b[39;00m\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1414\u001b[0m     request_body, json_size \u001b[38;5;241m=\u001b[39m \u001b[43m_get_inference_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_start\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msequence_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpriority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m request_compression_algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\tritonclient\\http\\_utils.py:109\u001b[0m, in \u001b[0;36m_get_inference_request\u001b[1;34m(inputs, request_id, outputs, sequence_id, sequence_start, sequence_end, priority, timeout, custom_parameters)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timeout\n\u001b[1;32m--> 109\u001b[0m infer_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [this_input\u001b[38;5;241m.\u001b[39m_get_tensor() \u001b[38;5;28;01mfor\u001b[39;00m this_input \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs:\n\u001b[0;32m    111\u001b[0m     infer_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    112\u001b[0m         this_output\u001b[38;5;241m.\u001b[39m_get_tensor() \u001b[38;5;28;01mfor\u001b[39;00m this_output \u001b[38;5;129;01min\u001b[39;00m outputs\n\u001b[0;32m    113\u001b[0m     ]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\tritonclient\\http\\_utils.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m timeout\n\u001b[1;32m--> 109\u001b[0m infer_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[43mthis_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tensor\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m this_input \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs:\n\u001b[0;32m    111\u001b[0m     infer_request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    112\u001b[0m         this_output\u001b[38;5;241m.\u001b[39m_get_tensor() \u001b[38;5;28;01mfor\u001b[39;00m this_output \u001b[38;5;129;01min\u001b[39;00m outputs\n\u001b[0;32m    113\u001b[0m     ]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute '_get_tensor'"
     ]
    }
   ],
   "source": [
    "infer_model(image=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678b0226-ee86-441e-aa0f-d5f3c6f46180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
